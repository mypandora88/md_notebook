## 智能驾驶必备技术
![](https://ddns.smpi.top:10000/md_attachments/Pasted%20image%2020220111140314.png)

从上面的无人驾驶汽车的结构图上，一个典型的无人驾驶系统，需要的传感器硬件有双/多目相机，深度相机、激光雷达、毫米波雷达， 这些传感器获取到的数据需要交给汽车的决策系统、中央计算处理系统来进行决策。

无人驾驶系统的核心框架，主要包含三个方面：感知，规划和控制。
- **感知**是指无人驾驶系统通过传感器从环境中收集信息，换大白话就是，我在哪里，我周围是啥。
- **规划**是指无人驾驶系统为了达到一个目的地要做出决策和计划的过程。大白话就是，give me a plan。
- **控制**是指根据上面感知和规划的内容，合理的控制油门，方向盘和刹车的过程。大白话就是，告诉我每一步我该怎么做。

那么个人想做无人驾驶开发，需要学习什么样的内容呢？

### Linux
汽车的中央处理系统需要一个稳定的计算平台，Linux操作系统是很多顶级汽车制造商首选的汽车开源软件平台。它已经取代无数专有或封闭的 操作系统。许多全球领先的汽车制造商将Linux作为操作系统，Linux已经存在了几十年，是非常稳定的高性能计算机操作系统。linux其实不难，linux是个工具，只要你多用，自然就熟悉了。

为了和机器人操作系统ROS兼容建议大家直接安装Ubuntu18.04或者20.04来熟悉linux。

开发环境：Linux

编程语言：命令行和shell命令

学习内容：常见linux命令， 网络操作，用户和权限操作，系统命令操作

### ROS
在无人驾驶中，我们需要综合应用各类算法，包括感知、定位、全局路径规划等算法。同时还要对车辆本身的各种硬件进行交互控制，包括油门、方向盘、摄像头，激光雷达，里程计等。 

我们需要一个操作系统来管理这么多复杂的工作，无人驾驶汽车就是一个特殊的机器人， ROS(机器人操作系统）可以很好的帮助我们解决这些问题。ROS可以通过点对点的传输形式或是广播的形式来做信号传输。 百度的阿波罗无人驾驶系统就是在ROS的基础上进行扩展开发的。

![](https://ddns.smpi.top:10000/md_attachments/Pasted%20image%2020220111140602.png)

ROS还提供了非常丰富的调试和仿真开发工具。

开发环境：Linux

编程语言：Python，c++，opencv

学习内容：ros开发环境，ros架构，topic，service，ros消息机制，日志，params和roslaunch，tf坐标变换和urdf仿真

### 定位系统
定位是无人驾驶的重要内容，核心就是解决我在哪，我要去哪的问题。

定位目前有两种比较成熟的技术，一种是采用三角定位法，使用GPS或者基站的方式定位，一种是使用slam算法基于视觉或者激光雷达方式的定位。

GPS原理是基于卫星的三角定位，室内环境我们可以用uwb芯片在室内模拟gps的开发。

目前SLAM （Simultaneous Localization and Mapping，即时定位与地图构建）也是非常常见的定位技术，有激光SLAM和视觉SLAM之分。激光slam使用雷达采集到的物体信息呈现出一系列分散的、具有准确角度和距离信息的点，被称为点云。通常，激光SLAM系统通过对不同时刻两片点云的匹配与比对，计算激光雷达相对运动的距离和姿态的改变，也就完成了对机器人自身的定位。

开发环境：Linux

编程语言：Python，c++，opencv

学习内容：梯度下降定位算法，gmapping， orbslam

### 传感器融合算法
多传感器融合可显著提高系统的冗余度和容错性，从而保证决策的快速性和正确性，是无人驾驶的必然趋势。各种传感器性能各有优劣，在不同的应用场景里都可以发挥独特的优势，仅依靠单一或少数传感器难以完成无人驾驶的使命。

特斯拉为了成本考虑不使用激光雷达进行自动驾驶，所以特斯拉经常跟白色的卡车过不去。

之前就有一次著名的自动驾驶事故,主要原因是特斯拉没有做好传感器融合融合的工作。视觉系统认为这么大一块白色一定是一朵白云, 毫米波雷达看到底下有一大块空间，认为可能是一个悬空的交通标识符。

最终两个传感器融合的结果就是可以通过。车辆未识别到横穿马路的一辆白色卡车，直接“尝试”从其下方钻过，导致车主不幸身亡。

现在美国很多有白色卡车的车主，特地贴上一个醒目的标签，让特斯拉别撞自己。

传感器融合算法在定位中也广泛使用， 通过IMU和轮速计，得到车辆初始的位置，而GPS则可以不断纠偏，把错误率控制在一定的范围，比如GPS是厘米级的，那么精度就能保证在厘米级别，同时再加上激光雷达和高精地图的匹配，得出一个最终的很精准的位置。

传感器融合主要使用的技术就是概率论和卡尔曼滤波。

![](https://ddns.smpi.top:10000/md_attachments/Pasted%20image%2020220111140923.png)

开发环境：Linux

编程语言：Python，c++，opencv

学习内容：激光雷达驱动，双目相机，概率论，贝叶斯概率，卡尔曼滤波，扩展卡尔曼滤波

### 车辆模型和控制
要想精准的控制小车，必须要熟悉闭环的控制理论。

通过运动控制，我们可以实现让车开的像老司机一样。

对自动驾驶来说，控制就是指使用方向盘、油门和刹车，将车驾驶到期望的位置。我们开车在十字路口或拐弯时候，可以凭着直觉和经验来决定拐弯的角度大小，加速的时机，以及是否需要刹车等。我们需要将这种直觉教给计算机。

我们经常把控制算法称之为控制器，PID控制器就是最常见、最基础的控制器之一。

![](https://ddns.smpi.top:10000/md_attachments/Pasted%20image%2020220111141022.png)

开发环境：Linux

编程语言：Python，c++，opencv

学习内容：控制论，pid控制器， Twiddle调校最优解

### 路径规划  
规划是自动驾驶系统中重要的一环，它的主要目的是：接收原始 / 预处理的外界信息，根据无人车行驶的目的地，规划出无人车的运动轨迹。根据对环境信息的掌握程度不同，路径规划可分为全局路径规划和局部路径规划 。

大家要掌握A_搜索算法等常用路径规划算法。A_搜索算法在自动驾驶领域多个层面都有应用，是经典的离散空间路径搜索算法。

开发环境：Linux

编程语言：Python，c++，opencv

学习内容：有向图，广度优先搜索算法，路径规划算法，A*算法

### 传统计算机视觉
机器视觉是人工智能正在快速发展的一个分支。简单说来，机器视觉就是用机器代替人眼来做测量和判断。机器视觉系统是通过机器视觉产品(即图像摄取装置，分CMOS和CCD两种)将被摄取目标转换成图像信号，传送给专用的图像处理系统，得到被摄目标的形态信息，根据像素分布和亮度、颜色等信息，转变成数字化信号;图像系统对这些信号进行各种运算来抽取目标的特征，进而根据判别的结果来控制现场的设备动作。

开发环境：Linux

编程语言：Python，c++，opencv

学习内容：图像变换，颜色空间，颜色过滤，二值化，卷积变换，边缘和轮廓提取，模板匹配，背景消除

### 卷积神经网络
卷积神经网络是一种特殊的神经网络结构，是自动驾驶汽车、人脸识别系统等领域有着广泛的应用，可以完成图像的侦测，识别，分割等功能

开发环境：Linux

编程：C/C++，Python，opencv，TensorFlow

学习内容：需要机器学习的基本算法 ( 降维、分类、回归等 )；需要学习深度学习，深度学习框架；学习计算机视觉和图像处理的常用方法 ( 物体检测、跟踪、分割、分类识别等 ) 。

### 行为克隆和强化学习
深度学习和强化学习在无人驾驶领域扮演着重要的角色。

深度学习提供了感知能力，但是缺乏一定的决策能力

强化学习提供了决策能力，非常适合做无人车决策规划

开发环境：Linux

编程：C/C++，Python，opencv，TensorFlow

学习内容：行为克隆，复现Nvidia论文

### 无人驾驶仿真技术
无人驾驶需要使用各种各样的传感器，学习成本较高，为了能低成本的学习无人驾驶技术，我们需要能够自主搭建无人驾驶的仿真环境。仿真环境可以基于合成的数据,对环境_、_感知及车辆进行模拟, 我们可以模拟激光雷达，模拟图像视觉的识别，通过仿真环境开发和验证算法。

开发环境：Linux

编程：C/C++，Python，opencv，TensorFlow

学习内容：webots，unity，ros